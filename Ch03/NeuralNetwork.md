# Chapter03 신경망

Chapter02에서 배운 퍼셉트론으로는 이론상 컴퓨터가 수행하는 복잡한 처리도 표현할 수 있었다. 
나쁜 소식은 가중치를 설정하는 작업은 여전히 사람이 수동적으로 해야한다는 것이다. 신경망(Neural Network)은
이 나쁜 소식을 해결해준다. 가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습하는 능력이 이제부터
살펴볼 신경망의 아주 중요한 성질이다. 이번 장에서는 신경망의 개요를 설명하고 신경망이 입력 데이터가
무엇인지 식별하는 처리 과정을 자세히 알아보겠다. 

## 3.1 퍼셉트론에서 신경망으로
신경망은 퍼셉트론과 공통점이 많다. 퍼셉트론과 다른 점을 중심으로 신경망의 구조를 설명할 것

### 3.1.1 신경망의 예
<img src="../dataset/mdImage/신경망.png" width="400" height="300">

- 은닉충의 뉴런은 입력층이나 출력층과 달리 사람 눈에는 보이지 않는다.
- 파이썬 배열의 인덱스가 0부터 시작하니 입력층에서 출력층 방향으로 0층부터 시작
- 그림에서는 입력층이 0층, 은닉층이 1층, 출력층이 2층이 된다.
> 신경망은 3층이지만 가중치를 갖는 층은 2개이므로 '2층 신경망'이라고 한다. 
> 하지만 문헌에 따라서는 '3층 신경망'이라고 하는 경우도 있다.
> 여기서는 가중치를 갖는 층의 개수를 기준으로 하겠다.


### 3.1.2 퍼셉트론 복습
<img src="../dataset/mdImage/biasPerceptron.png" width="300" height="300">

- 기존의 퍼셉트론에서 편향을 명시한 퍼셉트론을 그림으로 나타낸 것
- 가중치가 b이고 입력이 1인 뉴런이 추가 된 것이다.
- 동작은 x1, x2, 1 이라는 3개의 신호가 뉴런에 입력되어, 각 신호에 가중치를 곱한 후, 다음 뉴런에 전달된다.
- 다음 뉴런에서는 이 신호들의 값을 더하여 0을 넘으면 1을 출력, 그렇지 않으면 0을 출력한다.
- 조건 분기의 동작(0을 넘으면 1을 출력, 그렇지 않으면 0을 출력)을 하나의 함수로 나타낸 `h(x)`
  - y = h(b + w1*x1 + w2*x2)
  - h(x) = 0 (x <= 0), 1 (x > 0)

### 3.1.3 활성화 함수의 등장
- 조금 전 h(x)라는 함수가 등장했는데, 이처럼 입력 신호의 총합을 출력 신호로 변환 하는 함수를 
일반적으로 `활성화 함수(activation function)`라고 한다.
- 3.1.2의 h(x)수식에서 입력 값을 a로 치환하면
  - a = b + w1*x1 + w2*x2
  - y = h(a)
- 가중치가 달린 입력 신호와 편향의 총합을 계산하고, 이를 a라고 한다. 그리고 a를 함수 h()에 넣어 
y를 출력하는 흐름이고 이를 그려보면 다음과 같다.

<img src="../dataset/mdImage/활성화함수의처리과정.png" width="300" height="300">

> 신경망의 동작을 더 명확히 드러내고자 할 때는 다음 그림처럼 활성화 처리 과정을 명시하기도 한다.
> 이 활성화 함수가 퍼셉트론에서 신경망으로 가기 위한 길잡이다.


## 3.2 활성화 함수
- 임계값을 경계로 출력이 바뀌는 함수를 `계단 함수 (Step Function)`이라고 한다.
- 여태껏 (퍼셉트론에서는) 활성화 함수로 계단 함수를 이용했다.
- 즉, 확성화 함수로 쓸 수 있는 여러 후보 중 퍼셉트론은 계단 함수를 채용 한 것.
- `이러한 활성화 함수를 계단 함수에서 다른 함수로 변경 하는 것이 신경망으로 나아가는 방법이다.`

### 3.2.1 시그모이드 함수
- 다음은 신경망에서 자주 이용하는 활성화 함수인 `시그모이드 함수(sigmoid function)`를 나타낸 식이다.
- 식 h(x) = 1 / 1 + exp(-x), 여기서 exp(-x) = e ^ -x 이다.
- 신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고 변환된 신호를 다음 뉴런에 전달
- `사실 앞 장에서 본 퍼셉트론과 신경망의 주된 차이는 이 활성화 함수 뿐이다.`
- 그 외에 뉴런이 여러 층으로 이어지는 구조와 신호를 전달하는 방법은 기본적으로 앞에서 살펴본 퍼셉트론과 비슷

### 3.2.1 계단 함수 구현하기
```python
import numpy as np

def step_function(x):
    return np.array(x > 0, dtype=int)

x = np.array([-1.0, 2.0, 3.0, 4.0, 5.0, 6.0])
y = step_function(x)
print(y)
```
```
결과 출력 :

[0 1 1 1 1 1]
```
- numpy를 통해 배열을 생성했다.
- 이떄 x > 0 의 결과는 bool 배열이므로 dtype=int 를 통해 자료형을 변환하였음

### 3.2.2 계단 함수의 그래프
```python
import numpy as np
import matplotlib.pylab as plt

def step_function(x):
    return np.array(x > 0, dtype=int)

x_graph = np.arange(-5.0, 5.0, 0.1)
y = step_function(x_graph)
plt.plot(x_graph,y)
plt.ylim(-0.1, 1.1) # y축 범위 지정
plt.show()
```
- matplotlib 라이브러리 사용
- np.aranage를 통해 -5.0 ~ 5.0 전까지 0.1 간격의 넘파이 배열 생성
- step_function()은 인수로 받은 넘파이 배열의 원소 각각을 인수로 계단 함수 실행해, 
그 결과를 다시 배열로 만들어 돌려준다.
- 이 x,y 배열을 그래프로 그린(plot) 결과
<img src="../dataset/mdImage/stepFunction" width="400" height="300">


### 3.2.4 시그모이드 함수 구현하기

